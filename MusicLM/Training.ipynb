{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: musiclm-pytorch in /opt/conda/lib/python3.10/site-packages (0.2.2)\n",
      "Collecting torch==1.13.1+cu117\n",
      "  Downloading https://download.pytorch.org/whl/cu117/torch-1.13.1%2Bcu117-cp310-cp310-linux_x86_64.whl (1801.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.14.1+cu117\n",
      "  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.14.1%2Bcu117-cp310-cp310-linux_x86_64.whl (24.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchtext==0.14.1\n",
      "  Downloading torchtext-0.14.1-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchaudio==0.13.1 in /opt/conda/lib/python3.10/site-packages (0.13.1+cu116)\n",
      "Collecting torchdata==0.5.1\n",
      "  Downloading torchdata-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.13.1+cu117) (4.6.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.14.1+cu117) (1.24.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.14.1+cu117) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.14.1+cu117) (9.5.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext==0.14.1) (4.65.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.5.1) (1.26.16)\n",
      "Requirement already satisfied: portalocker>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.5.1) (2.7.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from musiclm-pytorch) (0.20.3)\n",
      "Requirement already satisfied: audiolm-pytorch>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from musiclm-pytorch) (1.2.7)\n",
      "Requirement already satisfied: beartype in /opt/conda/lib/python3.10/site-packages (from musiclm-pytorch) (0.14.1)\n",
      "Requirement already satisfied: einops>=0.6 in /opt/conda/lib/python3.10/site-packages (from musiclm-pytorch) (0.6.1)\n",
      "Requirement already satisfied: lion-pytorch in /opt/conda/lib/python3.10/site-packages (from musiclm-pytorch) (0.1.2)\n",
      "Requirement already satisfied: vector-quantize-pytorch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from musiclm-pytorch) (1.6.24)\n",
      "Requirement already satisfied: x-clip in /opt/conda/lib/python3.10/site-packages (from musiclm-pytorch) (0.12.1)\n",
      "Requirement already satisfied: ema-pytorch>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.2.3)\n",
      "Requirement already satisfied: encodec in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.1.1)\n",
      "Requirement already satisfied: fairseq in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.12.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.2.0)\n",
      "Requirement already satisfied: local-attention>=1.8.4 in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.8.6)\n",
      "Requirement already satisfied: scikit-learn==0.24.0 in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.24.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.1.99)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (4.30.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==0.24.0->audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==0.24.0->audiolm-pytorch>=0.17.0->musiclm-pytorch) (3.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm-pytorch) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm-pytorch) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm-pytorch) (6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.14.1+cu117) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.14.1+cu117) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.14.1+cu117) (2023.5.7)\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (from x-clip->musiclm-pytorch) (6.1.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from x-clip->musiclm-pytorch) (2023.6.3)\n",
      "Requirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.15.1)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.29.35)\n",
      "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.0.7)\n",
      "Requirement already satisfied: omegaconf<2.1 in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (2.0.6)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (2.3.1)\n",
      "Requirement already satisfied: bitarray in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (2.7.5)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ftfy->x-clip->musiclm-pytorch) (0.2.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.15.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.3.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch) (2023.5.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /opt/conda/lib/python3.10/site-packages (from hydra-core<1.1,>=1.0.7->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (4.8)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (4.9.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (2.21)\n",
      "Installing collected packages: torch, torchvision, torchtext, torchdata\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.14.1+cu116\n",
      "    Uninstalling torchvision-0.14.1+cu116:\n",
      "      Successfully uninstalled torchvision-0.14.1+cu116\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.15.2\n",
      "    Uninstalling torchtext-0.15.2:\n",
      "      Successfully uninstalled torchtext-0.15.2\n",
      "  Attempting uninstall: torchdata\n",
      "    Found existing installation: torchdata 0.6.1\n",
      "    Uninstalling torchdata-0.6.1:\n",
      "      Successfully uninstalled torchdata-0.6.1\n",
      "Successfully installed torch-1.13.1+cu117 torchdata-0.5.1 torchtext-0.14.1 torchvision-0.14.1+cu117\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %%python3 -m ipykernel install --user --name=musiclm\n",
    "\n",
    "%pip install musiclm-pytorch torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrogram yielded shape of (65, 86), but had to be cropped to (64, 80) to be patchified for transformer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from musiclm_pytorch import MuLaN, AudioSpectrogramTransformer, TextTransformer\n",
    "\n",
    "audio_transformer = AudioSpectrogramTransformer(\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    dim_head = 64,\n",
    "    spec_n_fft = 128,\n",
    "    spec_win_length = 24,\n",
    "    spec_aug_stretch_factor = 0.8\n",
    ")\n",
    "\n",
    "text_transformer = TextTransformer(\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    dim_head = 64,\n",
    ")\n",
    "\n",
    "mulan = MuLaN(\n",
    "    audio_transformer = audio_transformer,\n",
    "    text_transformer = text_transformer,\n",
    ")\n",
    "\n",
    "wavs = torch.randn(2,1024)\n",
    "texts = torch.randint(0, 20000, (2, 256))\n",
    "\n",
    "loss = mulan(wavs, texts)\n",
    "loss.backward()\n",
    "\n",
    "embeds=mulan.get_audio_latents(wavs) # during training\n",
    "# embeds=mulan.get_audio_latents(texts) # during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from musiclm_pytorch import MuLaNEmbedQuantizer\n",
    "\n",
    "quantizer = MuLaNEmbedQuantizer(\n",
    "    mulan = mulan,\n",
    "    conditioning_dims = (1024,1024,1024),\n",
    "    namespaces = ('semantics', 'coarse', 'fine'),\n",
    ")\n",
    "\n",
    "# now say you want the conditioning embeddings for semantic transformer\n",
    "\n",
    "wavs = torch.randn(2,1024)\n",
    "conds = quantizer(wavs=wavs, namespace='semantics') # (2,8,1024) - 8 is number of quantizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">16</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>audio_text_condition = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this must be set to True (same for CoarseTransfor</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span>).cuda()                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>16 trainer = SemanticTransformerTrainer(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>transformer = semantic_transformer,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>wav2vec = wav2vec,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>audio_conditioner = quantizer,   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># pass in the MulanEmbedQuantizer instance above</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">116</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/audiolm_pytorch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">606</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 603 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> exists(data_max_length_seconds):                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 604 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>data_max_length = data_max_length_seconds * wav2vec.target_sample_hz      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 605 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 606 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ds = SoundDataset(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 607 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>folder,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 608 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>max_length = data_max_length,                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 609 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>target_sample_hz = wav2vec.target_sample_hz,                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">116</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/audiolm_pytorch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">46</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>):                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>path = Path(folder)                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 46 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> path.exists(), <span style=\"color: #808000; text-decoration-color: #808000\">'folder does not exist'</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 47 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 48 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>files = [file <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> ext <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> exts <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> file <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> path.glob(<span style=\"color: #808000; text-decoration-color: #808000\">f'**/*.{</span>ext<span style=\"color: #808000; text-decoration-color: #808000\">}'</span>)]                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 49 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(files) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'no sound files found'</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AssertionError: </span>folder does not exist\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m16\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   \u001b[0maudio_text_condition = \u001b[94mTrue\u001b[0m      \u001b[2m# this must be set to True (same for CoarseTransfor\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m).cuda()                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m16 trainer = SemanticTransformerTrainer(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   \u001b[0mtransformer = semantic_transformer,                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   \u001b[0mwav2vec = wav2vec,                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   \u001b[0maudio_conditioner = quantizer,   \u001b[2m# pass in the MulanEmbedQuantizer instance above\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m116\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/audiolm_pytorch/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m606\u001b[0m in \u001b[92m__init__\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 603 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m exists(data_max_length_seconds):                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 604 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdata_max_length = data_max_length_seconds * wav2vec.target_sample_hz      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 605 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 606 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.ds = SoundDataset(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 607 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfolder,                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 608 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmax_length = data_max_length,                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 609 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtarget_sample_hz = wav2vec.target_sample_hz,                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m116\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/audiolm_pytorch/\u001b[0m\u001b[1;33mdata.py\u001b[0m:\u001b[94m46\u001b[0m in \u001b[92m__init__\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m│   \u001b[0m):                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   │   \u001b[0mpath = Path(folder)                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 46 \u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m path.exists(), \u001b[33m'\u001b[0m\u001b[33mfolder does not exist\u001b[0m\u001b[33m'\u001b[0m                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 47 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 48 \u001b[0m\u001b[2m│   │   \u001b[0mfiles = [file \u001b[94mfor\u001b[0m ext \u001b[95min\u001b[0m exts \u001b[94mfor\u001b[0m file \u001b[95min\u001b[0m path.glob(\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33m**/*.\u001b[0m\u001b[33m{\u001b[0mext\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m)]                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 49 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mlen\u001b[0m(files) > \u001b[94m0\u001b[0m, \u001b[33m'\u001b[0m\u001b[33mno sound files found\u001b[0m\u001b[33m'\u001b[0m                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAssertionError: \u001b[0mfolder does not exist\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from audiolm_pytorch import HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer\n",
    "\n",
    "wav2vec = HubertWithKmeans(\n",
    "    checkpoint_path = './hubert/hubert_base_ls960.pt',\n",
    "    kmeans_path = './hubert/hubert_base_ls960_L9_km500.bin'\n",
    ")\n",
    "\n",
    "semantic_transformer = SemanticTransformer(\n",
    "    num_semantic_tokens = wav2vec.codebook_size,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    audio_text_condition = True      # this must be set to True (same for CoarseTransformer and FineTransformers)\n",
    ").cuda()\n",
    "\n",
    "trainer = SemanticTransformerTrainer(\n",
    "    transformer = semantic_transformer,\n",
    "    wav2vec = wav2vec,\n",
    "    audio_conditioner = quantizer,   # pass in the MulanEmbedQuantizer instance above\n",
    "    folder ='/path/to/audio/files',\n",
    "    batch_size = 1,\n",
    "    data_max_length = 320 * 32,\n",
    "    num_train_steps = 1\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musiclm",
   "language": "python",
   "name": "musiclm"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
