{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "0-dimensional argument does not have enough dimensions for all core dimensions ('m',)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m prompt \u001b[39m=\u001b[39m add_mode(i, mode, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, prompt)\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTho\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 60\u001b[0m     thought \u001b[39m=\u001b[39m complete(prompt, stop_at\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m     prompt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mthought\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAct\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/outlines/models/openai.py:84\u001b[0m, in \u001b[0;36mOpenAICompletion.<locals>.generate\u001b[0;34m(prompt, samples, stop_at, is_in, type)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m generate_choice(prompt, is_in, samples)\n\u001b[1;32m     83\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m generate_base(prompt, stop_at, samples, mask)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/outlines/base.py:48\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_thunk()\n\u001b[1;32m     47\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_with_signature(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_no_signature(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/outlines/base.py:134\u001b[0m, in \u001b[0;36mvectorize.call_with_signature\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m kwargs \u001b[39m=\u001b[39m {key: np\u001b[39m.\u001b[39marray(value) \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    131\u001b[0m \u001b[39m# Find the arguments' broadcast shape, and map placeholder\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m# variables in the signature to the number of dimensions\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m# they correspond to given the arguments.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m broadcast_shape, dim_sizes \u001b[39m=\u001b[39m _parse_input_dimensions(\n\u001b[1;32m    135\u001b[0m     args \u001b[39m+\u001b[39;49m \u001b[39mlist\u001b[39;49m(kwargs\u001b[39m.\u001b[39;49mvalues()), input_core_dims\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    138\u001b[0m \u001b[39m# Calculate the shape to which each of the arguments should be broadcasted\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m# and reshape them accordingly.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m input_shapes \u001b[39m=\u001b[39m _calculate_shapes(broadcast_shape, dim_sizes, input_core_dims)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2087\u001b[0m, in \u001b[0;36m_parse_input_dimensions\u001b[0;34m(args, input_core_dims)\u001b[0m\n\u001b[1;32m   2085\u001b[0m dim_sizes \u001b[39m=\u001b[39m {}\n\u001b[1;32m   2086\u001b[0m \u001b[39mfor\u001b[39;00m arg, core_dims \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(args, input_core_dims):\n\u001b[0;32m-> 2087\u001b[0m     _update_dim_sizes(dim_sizes, arg, core_dims)\n\u001b[1;32m   2088\u001b[0m     ndim \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(core_dims)\n\u001b[1;32m   2089\u001b[0m     dummy_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlib\u001b[39m.\u001b[39mstride_tricks\u001b[39m.\u001b[39mas_strided(\u001b[39m0\u001b[39m, arg\u001b[39m.\u001b[39mshape[:ndim])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2050\u001b[0m, in \u001b[0;36m_update_dim_sizes\u001b[0;34m(dim_sizes, arg, core_dims)\u001b[0m\n\u001b[1;32m   2048\u001b[0m num_core_dims \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(core_dims)\n\u001b[1;32m   2049\u001b[0m \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mndim \u001b[39m<\u001b[39m num_core_dims:\n\u001b[0;32m-> 2050\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2051\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-dimensional argument does not have enough \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2052\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdimensions for all core dimensions \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m   2053\u001b[0m         \u001b[39m%\u001b[39m (arg\u001b[39m.\u001b[39mndim, core_dims))\n\u001b[1;32m   2055\u001b[0m core_shape \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39mnum_core_dims:]\n\u001b[1;32m   2056\u001b[0m \u001b[39mfor\u001b[39;00m dim, size \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(core_dims, core_shape):\n",
      "\u001b[0;31mValueError\u001b[0m: 0-dimensional argument does not have enough dimensions for all core dimensions ('m',)"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\"\"\"ReAct\n",
    "\n",
    "This example was inspired by the LQML library [1]_. The ReAct framework was\n",
    "first developed in [2]_ and augments Chain-of-Thought prompting with the ability\n",
    "for the model to query external sources.\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1] Beurer-Kellner, L., Fischer, M., & Vechev, M. (2022). Prompting Is Programming: A Query Language For Large Language Models. arXiv preprint arXiv:2212.06094.\n",
    ".. [2] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022). React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629.\n",
    "\n",
    "\"\"\"\n",
    "import requests  # type: ignore\n",
    "\n",
    "import outlines.models as models\n",
    "import outlines.text as text\n",
    "\n",
    "\n",
    "@text.prompt\n",
    "def build_reAct_prompt(question):\n",
    "    \"\"\"What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n",
    "    Tho 1: I need to search Colorado orogeny, find the area that the eastern sector of the Colorado ...\n",
    "    Act 2: Search 'Colorado orogeny'\n",
    "    Obs 2: The Colorado orogeny was an episode of mountain building (an orogeny) ...\n",
    "    Tho 3: It does not mention the eastern sector. So I need to look up eastern sector.\n",
    "    ...\n",
    "    Tho 4: High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n",
    "    Act 5: Finish '1,800 to 7,000 ft'\n",
    "    {{ question }}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "@text.prompt\n",
    "def add_mode(i, mode, result, prompt):\n",
    "    \"\"\"{{ prompt }}\n",
    "    {{ mode }} {{ i }}: {{ result }}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def search_wikipedia(query: str):\n",
    "    url = f\"https://en.wikipedia.org/w/api.php?format=json&action=query&prop=extracts&exintro&explaintext&redirects=1&titles={query}&origin=*\"\n",
    "    response = requests.get(url)\n",
    "    page = response.json()[\"query\"][\"pages\"]\n",
    "    return \".\".join(list(page.values())[0][\"extract\"].split(\".\")[:2])\n",
    "\n",
    "\n",
    "prompt = build_reAct_prompt(\"Where is Apple Computers headquarted? \")\n",
    "complete = models.text_completion.openai(\n",
    "    \"gpt-3.5-turbo\", max_tokens=128, temperature=1.0\n",
    ")\n",
    "\n",
    "for i in range(1, 10):\n",
    "    mode = complete(prompt, is_in=[\"Tho\", \"Act\"])\n",
    "    prompt = add_mode(i, mode, \"\", prompt)\n",
    "\n",
    "    if mode == \"Tho\":\n",
    "        thought = complete(prompt, stop_at=\"\\n\")\n",
    "        prompt += f\"{thought}\"\n",
    "    elif mode == \"Act\":\n",
    "        action = complete(prompt, is_in=[\"Search\", \"Finish\"])\n",
    "        prompt += f\"{action} '\"\n",
    "\n",
    "        subject = complete(prompt, stop_at=[\"'\"])  # Apple Computers headquartered\n",
    "        subject = \" \".join(subject.split()[:2])\n",
    "        prompt += f\"{subject}'\"\n",
    "\n",
    "        if action == \"Search\":\n",
    "            result = search_wikipedia(subject)\n",
    "            prompt = add_mode(i, \"Obs\", result, prompt)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-playground",
   "language": "python",
   "name": "openai-playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
