{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.vectorstores.chroma.Chroma'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 79.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PDFPlumberLoader, DirectoryLoader\n",
    "from langchain.document_loaders.word_document import Docx2txtLoader\n",
    "from langchain.document_loaders.unstructured import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "cached_db = False\n",
    "loader_type = \"docx\"\n",
    "loader = None\n",
    "\n",
    "print(Chroma)\n",
    "if not cached_db:\n",
    "    if loader_type == \"pdf\":\n",
    "        loader_cls, glob = PDFPlumberLoader, \"*.pdf\"\n",
    "    elif loader_type == \"docx\":\n",
    "        loader_cls, glob = Docx2txtLoader, \"*.docx\"\n",
    "    elif loader_type == \"txt\":\n",
    "        loader_cls, glob = UnstructuredFileLoader, \"*.txt\"\n",
    "    else:\n",
    "        loader_cls, glob = None, None\n",
    "    loader = DirectoryLoader(\n",
    "        \"data/MGRP\", glob=glob, loader_cls=loader_cls, show_progress=True\n",
    "    )\n",
    "    pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync\n",
      "/home/jovyan/work/importer.py\n",
      "Number of pages: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 18:29:49.274490: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-10 18:29:49.405150: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-10 18:29:49.921291: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-10 18:29:49.921378: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-10 18:29:49.921387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-07-10 18:29:50.870256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-10 18:29:50.870560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-07-10 18:29:50.893764: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-07-10 18:29:50.893820: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%set_env PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync\n",
    "\n",
    "import importer\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "import tiktoken\n",
    "from langchain_extras.llms.exllama import ExLlama, BasicStreamingHandler\n",
    "from langchain.chains import loading, RetrievalQA\n",
    "\n",
    "handler = BasicStreamingHandler()\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "total_token_count = 0\n",
    "model_directory = \"models/TheBloke_GPT4All-13B-Snoozy-SuperHOT-8K-GPTQ\"\n",
    "\n",
    "print(f\"Number of pages: {len(pages)}\")\n",
    "\n",
    "llm = ExLlama(\n",
    "    streaming=True,\n",
    "    model_path=model_directory,\n",
    "    lora_path=None,\n",
    "    temperature=0.7,\n",
    "    beams=1,\n",
    "    beam_length=40,\n",
    "    stop_sequences=[\"Human:\", \"User:\", \"AI:\"],\n",
    "    callbacks=[handler],\n",
    "    verbose=False,\n",
    "    max_seq_len = 4096,\n",
    "    alpha_value=4.0,  # For use with any models\n",
    "    compress_pos_emb=4.0,  # For use with superhot\n",
    "    # set_auto_map = \"3, 2\" #Gpu split, this will split 3gigs/2gigs\n",
    ")\n",
    "\n",
    "\n",
    "def tiktoken_length(text):\n",
    "    global total_token_count\n",
    "    token_count = encoding.encode(text)\n",
    "    if len(token_count) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        total_token_count += token_count[0]\n",
    "        return token_count[0]\n",
    "\n",
    "texts = [p.page_content for p in pages]\n",
    "\n",
    "wizard_templte = \"\"\"You are a helpful AI Assistant. \n",
    "{history}\n",
    "### HUMAN: {input}\n",
    "### ASSISTANT: \"\"\"\n",
    "\n",
    "embeddings = SpacyEmbeddings()\n",
    "\n",
    "if cached_db:\n",
    "    db = Chroma(persist_directory=\"data\", embedding_function=embeddings)\n",
    "else:\n",
    "    db = Chroma.from_documents(pages, embeddings, persist_directory=\"data\")\n",
    "    db.persist()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=db.as_retriever(), verbose=True\n",
    ")\n",
    "    \n",
    "qa.save(\"data/chains/mgrp_chain.yaml\")\n",
    "handler.set_chain(qa.combine_documents_chain)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      " Yes, here's a summary of the story so far: After Tama dies from being killed by Swim, who becomes the new Master, Ripple tries to kill her former comrades one by one using their weapons. However, they are able to survive due to having been given special powers by Ruler before she died. They eventually find a way to defeat Ripple with the help of a magical phone and return to normal life. Meanwhile, Swim continues to be the Master while also trying to keep her identity hidden from others.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Yes, here's a summary of the story so far: After Tama dies from being killed by Swim, who becomes the new Master, Ripple tries to kill her former comrades one by one using their weapons. However, they are able to survive due to having been given special powers by Ruler before she died. They eventually find a way to defeat Ripple with the help of a magical phone and return to normal life. Meanwhile, Swim continues to be the Master while also trying to keep her identity hidden from others.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(\"Can you summarize the story?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-playground",
   "language": "python",
   "name": "openai-playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
