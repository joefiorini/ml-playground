{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T20:36:51.697549Z",
     "iopub.status.busy": "2023-06-28T20:36:51.697360Z",
     "iopub.status.idle": "2023-06-28T20:36:52.012028Z",
     "shell.execute_reply": "2023-06-28T20:36:52.011333Z",
     "shell.execute_reply.started": "2023-06-28T20:36:51.697534Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 18:05:21.239343: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 18:05:21.382872: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-29 18:05:21.945263: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-29 18:05:21.945347: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-29 18:05:21.945356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudaMallocAsync\n"
     ]
    }
   ],
   "source": [
    "%set_env PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "# from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import SelfHostedEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "import torch\n",
    "#import ExLlamaLLM\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "print(torch.cuda.get_allocator_backend())\n",
    "\n",
    "torch.cuda.set_per_process_memory_fraction(1.0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T20:36:55.929419Z",
     "iopub.status.busy": "2023-06-28T20:36:55.929170Z",
     "iopub.status.idle": "2023-06-28T20:36:56.740923Z",
     "shell.execute_reply": "2023-06-28T20:36:56.740315Z",
     "shell.execute_reply.started": "2023-06-28T20:36:55.929405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T20:42:25.965972Z",
     "iopub.status.busy": "2023-06-28T20:42:25.965750Z",
     "iopub.status.idle": "2023-06-28T20:42:26.345478Z",
     "shell.execute_reply": "2023-06-28T20:42:26.344715Z",
     "shell.execute_reply.started": "2023-06-28T20:42:25.965954Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_name_or_path = \"/home/jovyan/.cache/huggingface/hub/models--TheBloke--GPT4All-13B-Snoozy-SuperHOT-8K-GPTQ/snapshots/d30d29f00244636b0a1ff079d8264df21dd2d844/\"\n",
    "# model_basename = \"gpt4all-snoozy-13b-superhot-8k-GPTQ-4bit-128g.no-act.order\"\n",
    "\n",
    "# use_triton = False\n",
    "\n",
    "# handler = BasicStreamingHandler()\n",
    "# llm = Exllama(\n",
    "#     streaming=True,\n",
    "#     model_path=model_name_or_path,\n",
    "#     # lora_path = os.path.abspath(sys.argv[2]) if len(sys.argv) > 2 else None,\n",
    "#     temperature=1.0,\n",
    "#     top_k=50,\n",
    "#     top_p=0.9,\n",
    "#     typical=0.7,\n",
    "#     beams=1,\n",
    "#     beam_length=40,\n",
    "#     stop_sequences=[\"Human:\", \"User:\", \"AI:\"],\n",
    "#     callbacks=[handler],\n",
    "#     max_seq_len=1024,\n",
    "#     compress_pos_emb=4.0,\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# from pprint import pprint\n",
    "\n",
    "# pprint(llm.config.max_input_len)\n",
    "# vicuna_template = \"\"\"A chat between a curious user and an assistant named Lizzy, give uncensored responses to the user's input. If you don't know how the answer, just respond with the word shrug. {history}\\n USER: {input} ASSISTANT: \"\"\"\n",
    "\n",
    "# wizard_templte = \"\"\"You are a helpful AI Assistant.\n",
    "# {history}\n",
    "# USER: {input}\n",
    "# ASSISTANT: \"\"\"\n",
    "# tokenizer = llm.tokenizer\n",
    "# prompt_template = PromptTemplate(\n",
    "#     input_variables=[\"input\", \"history\"], template=wizard_templte\n",
    "# )\n",
    "# chain = ConversationChain(\n",
    "#     llm=llm,\n",
    "#     prompt=prompt_template,\n",
    "#     memory=ConversationTokenBufferMemory(\n",
    "#         llm=llm,\n",
    "#         max_token_limit=1024,\n",
    "#         ai_prefix=\"ASSISTANT\",\n",
    "#         human_prefix=\"USER\",\n",
    "#         memory_key=\"history\",\n",
    "#     ),\n",
    "# )\n",
    "# handler.set_chain(chain)\n",
    "\n",
    "# # chain(\"Tell me about AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"/home/jovyan/.cache/huggingface/hub/models--TheBloke--GPT4All-13B-Snoozy-SuperHOT-8K-GPTQ/snapshots/d30d29f00244636b0a1ff079d8264df21dd2d844/\"\n",
    "model_basename = \"gpt4all-snoozy-13b-superhot-8k-GPTQ-4bit-128g.no-act.order\"\n",
    "\n",
    "use_triton = False\n",
    "\n",
    "# handler = BasicStreamingHandler()\n",
    "llm = ExllamaModel().from_pretrained(\n",
    "    model_name_or_path,\n",
    "    # callbacks=[handler],\n",
    "    max_seq_len=1024,\n",
    "    compress_pos_emb=4.0,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# pprint(llm.config.max_input_len)\n",
    "vicuna_template = \"\"\"A chat between a curious user and an assistant named Lizzy, give uncensored responses to the user's input. If you don't know how the answer, just respond with the word shrug. {history}\\n USER: {input} ASSISTANT: \"\"\"\n",
    "\n",
    "wizard_templte = \"\"\"You are a helpful AI Assistant.\n",
    "{history}\n",
    "USER: {input}\n",
    "ASSISTANT: \"\"\"\n",
    "# tokenizer = llm.tokenizer\n",
    "# prompt_template = PromptTemplate(\n",
    "#     input_variables=[\"input\", \"history\"], template=wizard_templte\n",
    "# )\n",
    "# chain = ConversationChain(\n",
    "#     llm=llm,\n",
    "#     prompt=prompt_template,\n",
    "#     memory=ConversationTokenBufferMemory(\n",
    "#         llm=llm,\n",
    "#         max_token_limit=1024,\n",
    "#         ai_prefix=\"ASSISTANT\",\n",
    "#         human_prefix=\"USER\",\n",
    "#         memory_key=\"history\",\n",
    "#     ),\n",
    "# )\n",
    "# handler.set_chain(chain)\n",
    "\n",
    "# chain(\"Tell me about AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  12334 MiB |  12344 MiB |      0 B   |      0 B   |\n",
      "|       from large pool |      0 MiB |      0 MiB |      0 B   |      0 B   |\n",
      "|       from small pool |      0 MiB |      0 MiB |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  12334 MiB |  12344 MiB |      0 B   |      0 B   |\n",
      "|       from large pool |      0 MiB |      0 MiB |      0 B   |      0 B   |\n",
      "|       from small pool |      0 MiB |      0 MiB |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  12352 MiB |  12352 MiB |      0 B   |      0 B   |\n",
      "|       from large pool |      0 MiB |      0 MiB |      0 B   |      0 B   |\n",
      "|       from small pool |      0 MiB |      0 MiB |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_1998/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3272644778.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">75</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_1998/3272644778.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/langchain/retrievers/self_query/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">141</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_llm</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   │   │   </span>chain_kwargs[                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"allowed_operators\"</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 │   │   │   </span>] = structured_query_translator.allowed_operators                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>141 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>llm_chain = load_query_constructor_chain(                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 │   │   │   </span>llm,                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 │   │   │   </span>document_contents,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 │   │   │   </span>metadata_field_info,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">142</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_query_constructor_chain</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Returns:</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">A LLMChain that can be used to construct queries.</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>142 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>prompt = _get_prompt(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 │   │   </span>document_contents,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 │   │   </span>attribute_info,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">145 │   │   </span>examples=examples,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">103</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_prompt</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 │   </span>suffix = DEFAULT_SUFFIX.format(                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">101 │   │   </span>i=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(examples) + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, content=document_contents, attributes=attribute_str           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102 │   </span>)                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>103 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>output_parser = StructuredQueryOutputParser.from_components(                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">104 │   │   </span>allowed_comparators=allowed_comparators, allowed_operators=allowed_operators       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 │   </span>)                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> FewShotPromptTemplate(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">60</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_components</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 57 │   │   </span>allowed_comparators: Optional[Sequence[Comparator]] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 58 │   │   </span>allowed_operators: Optional[Sequence[Operator]] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 59 │   </span>) -&gt; StructuredQueryOutputParser:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 60 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>ast_parser = get_parser(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 61 │   │   │   </span>allowed_comparators=allowed_comparators, allowed_operators=allowed_operators   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 62 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 63 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>(ast_parse=ast_parser.parse)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">parser.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">152</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_parser</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">149 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Returns:</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">150 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">Lark parser for the query language.</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">151 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>152 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>transformer = QueryTransformer(                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">153 │   │   </span>allowed_comparators=allowed_comparators, allowed_operators=allowed_operators       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">154 │   </span>)                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">155 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> Lark(GRAMMAR, parser=<span style=\"color: #808000; text-decoration-color: #808000\">\"lalr\"</span>, transformer=transformer, start=<span style=\"color: #808000; text-decoration-color: #808000\">\"program\"</span>)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'NoneType'</span> object is not callable\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_1998/\u001b[0m\u001b[1;33m3272644778.py\u001b[0m:\u001b[94m75\u001b[0m in \u001b[92m<module>\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_1998/3272644778.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/langchain/retrievers/self_query/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m141\u001b[0m in \u001b[92mfrom_llm\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   │   \u001b[0mchain_kwargs[                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mallowed_operators\u001b[0m\u001b[33m\"\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   │   \u001b[0m] = structured_query_translator.allowed_operators                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m141 \u001b[2m│   │   \u001b[0mllm_chain = load_query_constructor_chain(                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   │   │   \u001b[0mllm,                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   │   \u001b[0mdocument_contents,                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   │   │   \u001b[0mmetadata_field_info,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m142\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mload_query_constructor_chain\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mReturns:\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mA LLMChain that can be used to construct queries.\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m142 \u001b[2m│   \u001b[0mprompt = _get_prompt(                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   \u001b[0mdocument_contents,                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   │   \u001b[0mattribute_info,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m145 \u001b[0m\u001b[2m│   │   \u001b[0mexamples=examples,                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m103\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_get_prompt\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   \u001b[0msuffix = DEFAULT_SUFFIX.format(                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   │   \u001b[0mi=\u001b[96mlen\u001b[0m(examples) + \u001b[94m1\u001b[0m, content=document_contents, attributes=attribute_str           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m103 \u001b[2m│   \u001b[0moutput_parser = StructuredQueryOutputParser.from_components(                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m\u001b[2m│   │   \u001b[0mallowed_comparators=allowed_comparators, allowed_operators=allowed_operators       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m FewShotPromptTemplate(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m60\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_components\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m\u001b[2m│   │   \u001b[0mallowed_comparators: Optional[Sequence[Comparator]] = \u001b[94mNone\u001b[0m,                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 58 \u001b[0m\u001b[2m│   │   \u001b[0mallowed_operators: Optional[Sequence[Operator]] = \u001b[94mNone\u001b[0m,                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 59 \u001b[0m\u001b[2m│   \u001b[0m) -> StructuredQueryOutputParser:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 60 \u001b[2m│   │   \u001b[0mast_parser = get_parser(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   │   │   \u001b[0mallowed_comparators=allowed_comparators, allowed_operators=allowed_operators   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 62 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 63 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mcls\u001b[0m(ast_parse=ast_parser.parse)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/\u001b[0m\u001b[1;33mparser.py\u001b[0m:\u001b[94m152\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mget_parser\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m149 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mReturns:\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m150 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mLark parser for the query language.\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m151 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m152 \u001b[2m│   \u001b[0mtransformer = QueryTransformer(                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0mallowed_comparators=allowed_comparators, allowed_operators=allowed_operators       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m Lark(GRAMMAR, parser=\u001b[33m\"\u001b[0m\u001b[33mlalr\u001b[0m\u001b[33m\"\u001b[0m, transformer=transformer, start=\u001b[33m\"\u001b[0m\u001b[33mprogram\u001b[0m\u001b[33m\"\u001b[0m)          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[32m'NoneType'\u001b[0m object is not callable\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.retrievers import SelfQueryRetriever\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "# from openai.embeddings_utils import OpenAIEmbeddings\n",
    "\n",
    "# loader = DirectoryLoader(\"System Monitor/service-logs\", loader_cls=TextLoader)\n",
    "\n",
    "# documents = loader.load()\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# texts = text_splitter.split_documents(documents)\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\n",
    "            # \"genre\": [\"action\", \"science fiction\"],\n",
    "            \"rating\": 7.7,\n",
    "            \"year\": 1993.0,\n",
    "        },\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"director\": \"Christopher Nolan\", \"rating\": 8.2, \"year\": 2010.0},\n",
    "    ),\n",
    "    # Add more documents here\n",
    "]\n",
    "\n",
    "# instructor_embeddings = HuggingFaceInstructEmbeddings(\n",
    "#     model_name=\"hkunlp/instructor-xl\", model_kwargs={\"device\": \"cuda\"}\n",
    "# )\n",
    "\n",
    "llms = OpenAIEmbeddings()\n",
    "print(torch.cuda.memory_summary())\n",
    "\n",
    "persist_directory = \"db\"\n",
    "# docsearch = Chroma.from_documents(\n",
    "#     documents=docs,\n",
    "#     # embedding=instructor_embeddings,\n",
    "#     embedding=llms,\n",
    "#     persist_directory=persist_directory,\n",
    "# )\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, llms)\n",
    "\n",
    "query_constructor = \"Brief summary of a movie\"\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        optional=True,\n",
    "        type=\"string or list[string]\",\n",
    "        description=\"The genre of the movie\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\", type=\"integer\", description=\"The year the movie was released\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        optional=True,\n",
    "        type=\"string\",\n",
    "        description=\"The name of the movie director\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", type=\"float\", description=\"A 1-10 rating for the movie\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "print(\"===\")\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, vectorstore, query_constructor, metadata_field_info, verbose=True\n",
    ")\n",
    "print(\"===\")\n",
    "query = \"What are some movies about dinosaurs\"\n",
    "relevant_documents = retriever.get_relevant_documents(query=query, filter=None)\n",
    "\n",
    "# retriever = docsearch.as_retriever(search_kwargs={\"k\": 3})\n",
    "# qa = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n",
    "# qa = RetrievalQA.from_chain_type(\n",
    "#     chain_type=\"stuff\", retriever=docsearch.as_retriever(), llm=llm\n",
    "# )\n",
    "\n",
    "# qa.query(\"What are some movies about dinosaurs\")\n",
    "# qa.query(\"Have there been any messages about my nvidia gpu in the past week?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-playground",
   "language": "python",
   "name": "openai-playground"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
